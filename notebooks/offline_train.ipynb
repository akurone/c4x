{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Offline Eğitim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hazırlık"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "root = Path.cwd().parents[0]\n",
    "if root not in sys.path:\n",
    "  sys.path.append(str(root))\n",
    "  sys.path.append(str(root / 'src'))\n",
    "\n",
    "TMP_DIR, DM_MDL_DIR = str(root / 'tmp'), str(root / 'serializedObjs' / 'dm')\n",
    "import os\n",
    "if not os.path.exists(TMP_DIR):\n",
    "  os.makedirs(TMP_DIR)\n",
    "if not os.path.exists(DM_MDL_DIR):\n",
    "  os.makedirs(DM_MDL_DIR)\n",
    "\n",
    "from src import utils\n",
    "utils.seed_everything()\n",
    "\n",
    "import pickle\n",
    "\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.models.gpt2.configuration_gpt2 import GPT2Config\n",
    "\n",
    "from src.decision_mamba import TrainableDM, DecisionMambaGymDataCollator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parametreler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_IN = f'{TMP_DIR}/offline_data.pkl'\n",
    "MDL_OUT = f'{DM_MDL_DIR}/test_offline'\n",
    "FRACTION = 0.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Veri Okuma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(DATA_IN):\n",
    "  raise FileExistsError(f\"Dosya ({DATA_IN}) bulunamadı.\")\n",
    "\n",
    "with open(DATA_IN, 'rb') as f:\n",
    "  gameReplayData = pickle.load(f)\n",
    "\n",
    "dataset = gameReplayData[:int(FRACTION * len(gameReplayData))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eğitim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 00:38, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=10, training_loss=2.0070676803588867, metrics={'train_runtime': 45.5456, 'train_samples_per_second': 8.782, 'train_steps_per_second': 0.22, 'total_flos': 0.0, 'train_loss': 2.0070676803588867, 'epoch': 5.0})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training Arguments\n",
    "training_args = TrainingArguments(\n",
    "  output_dir=f\"{TMP_DIR}/train_of/\",\n",
    "  remove_unused_columns=False,\n",
    "  num_train_epochs=5, #30, # 120\n",
    "  per_device_train_batch_size=64,\n",
    "  learning_rate=1e-4,\n",
    "  weight_decay=1e-4,\n",
    "  warmup_ratio=0.1,\n",
    "  optim=\"adamw_torch\",\n",
    "  max_grad_norm=0.25,\n",
    "  report_to=\"none\",\n",
    ")\n",
    "\n",
    "# Initialize and then train the model\n",
    "collator = DecisionMambaGymDataCollator(dataset)\n",
    "n_state, n_action, n_hidden = collator.state_dim, collator.act_dim, 64\n",
    "config = GPT2Config(\n",
    "      vocab_size=1, # doesn't matter -- we don't use the vocab\n",
    "      n_embd=n_hidden,\n",
    "      n_positions=n_action,\n",
    "      drop_p=0.1,\n",
    "      n_layer=6, #12\n",
    "      n_inner=4, #4\n",
    "      max_ep_len=n_state,\n",
    "      state_dim=n_state,\n",
    "      act_dim=n_action,\n",
    "      action_tanh=True,\n",
    "      remove_act_embs=True)\n",
    "model = TrainableDM(config)\n",
    "\n",
    "trainer = Trainer(\n",
    "  model=model,\n",
    "  args=training_args,\n",
    "  train_dataset=dataset,\n",
    "  data_collator=collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kayıt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(MDL_OUT)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
